{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APS8 - Regressão e Intervalo de Confiança\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Questão 1**\n",
    "\n",
    "*(Montgomery 6-1)*\n",
    "\n",
    "A indústria de *fast food* precisa selecionar materiais biodegradáveis para produzir embalagens mais sustentáveis. É desejável que o material tenha um baixo fator $\\kappa$ de condutividade térmico  (medido em W/mK). \n",
    "\n",
    "Uma abordagem para diminuir o $\\kappa$ é reduzir a densidade do material (medida em $g/cm^3$ )\n",
    "\n",
    "Assuma que é possível ajustar os dados por um modelo de regressão linear.\n",
    "\n",
    "\n",
    "| y: Condutividade termal (W/mK)| x: Densidade de produto (g/cm3)|\n",
    "|---|---|\n",
    "|0.0480| 0.1750|\n",
    "|0.0525| 0.2200|\n",
    "|0.0540| 0.2250|\n",
    "|0.0535| 0.2260|\n",
    "|0.0570| 0.2500|\n",
    "|0.0610| 0.2765|\n",
    "\n",
    "Linhas separadas:\n",
    "\n",
    "    condutividade = [0.0480, 0.0525, 0.0540, 0.0535, 0.0570, 0.0610]\n",
    "\n",
    "    densidade = [0.1750, 0.2200, 0.2250, 0.2260, 0.2500, 0.2765]\n",
    "\n",
    "Pede-se:\n",
    "\n",
    "**a.** Estime o modelo de regressão encontrando $\\hat{\\beta_0}$ e $\\hat{\\beta_1}$ usandos a fórmula abaixos. \n",
    "\n",
    "\n",
    "$$\\hat{\\beta_{0}} = \\bar{y} - \\hat{\\beta_1} \\bar{x}$$\n",
    "\n",
    "e\n",
    "\n",
    "$$\\hat{\\beta_1}= \\frac{\\sum\\limits_{i=1}^{n}(x_{i}-\\bar{x})(y_{i}-\\bar{y})}{\\sum\\limits_{i=1}^{n}(y_{i}-\\bar{y})^2} = \\frac{S_{xy}}{S_{xx}} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Dica:**  converta as listas em array do numpy. Desta forma **não vai precisar fazer loops.**\n",
    "\n",
    "    x = np.array(condutividade)\n",
    "    x_ = np.mean(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b0 é: -0.19\n",
      "b1 é: 7.67\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "condutividade = [0.0480, 0.0525, 0.0540, 0.0535, 0.0570, 0.0610]\n",
    "x = np.array(condutividade)\n",
    "xb = np.mean(x)\n",
    "\n",
    "densidade = [0.1750, 0.2200, 0.2250, 0.2260, 0.2500, 0.2765]\n",
    "y = np.array(densidade)\n",
    "yb= np.mean(y)\n",
    "\n",
    "## calcular sxx e sxy\n",
    "sxy = ((x-xb)*(y-yb)).sum()\n",
    "sxx = ((x-xb)**2).sum()\n",
    "b1 = sxy/sxx\n",
    "b0 = yb-b1*xb\n",
    "\n",
    "\n",
    "print(\"b0 é: {:.2f}\".format(b0))\n",
    "print (\"b1 é: {:.2f}\".format(b1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Por exemplo, a linha abaixo calcula $(x_i - \\overline{x})^2$ para todo $x_i$ de uma vez:\n",
    "\n",
    "    (x - x_)**2    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.01111111e-05, 3.36111111e-06, 1.11111111e-07, 6.94444444e-07,\n",
       "       7.11111111e-06, 4.44444444e-05])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x - x_)**2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E a linha abaixo calcula $\\sum\\limits_{i=1}^{n}(x_{i}-\\bar{x})$:\n",
    "\n",
    "    np.sum((x - x_)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.583333333333332e-05"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((x - x_)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**c.** Calcule $SS_E$ (SQRes) e encontre a variância dos resíduos. Veja o formulário que foi fornecido.\n",
    "\n",
    "$$SQRes=SS_{E}=\\sum\\limits^{n}_{i=1}(y_i-\\hat{y}_i)^2=\\sum\\limits_{i=1}^{n}\\epsilon^2_{i}$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**d.** Demonstre que $SQT = SQRes + SQReg$, ou, em outra notação,  que $SS_T = SS_R + SS_E$ . Ofereça uma explicação sucinta do que são SQT, SQRes e SQReg.\n",
    "\n",
    "$$SQReg=SS_{R}=(\\hat{y}_i-\\bar{y})^2$$\n",
    "\n",
    "$$SQT=SS_{T}=\\sum\\limits^{n}_{i=1}(y_i-\\bar{y})^2$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**e.**  Calcule o coeficiente de determinação $R^2$ . \n",
    "\n",
    "Faça um teste $t$ da significância estatística de $\\hat{\\beta_0}$ e $\\hat{\\beta_1}$ para um $\\alpha=5\\%$ . Deixe claras as hipóteses e forneça os níveis descritivos (*p-values*) dos resultados. \n",
    "\n",
    "**Dica:** \n",
    "\n",
    "Os valores $P > |t|$ que são dados no resultado da regressão são estes *p-values*\n",
    "\n",
    "**e.** Para $x = 0.0540$ quanto vale o resíduo do modelo de regressão? Quanto da variação é explicada pela regressão?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b.** Agora use a biblioteca `statsmodels` para encontrar $\\hat{\\beta_0}$ e $\\hat{\\beta_1}$. Escreva a equação que estima *Condutividade termal* em função da *Densidade do produto*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/anaconda3/lib/python3.6/site-packages/statsmodels/stats/stattools.py:72: ValueWarning: omni_normtest is not valid with less than 8 observations; 6 samples were given.\n",
      "  \"samples were given.\" % int(n), ValueWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.986</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.982</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   275.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 02 Nov 2018</td> <th>  Prob (F-statistic):</th> <td>7.70e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:21:35</td>     <th>  Log-Likelihood:    </th> <td>  25.097</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>     6</td>      <th>  AIC:               </th> <td>  -46.19</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>     4</td>      <th>  BIC:               </th> <td>  -46.61</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -0.1880</td> <td>    0.025</td> <td>   -7.471</td> <td> 0.002</td> <td>   -0.258</td> <td>   -0.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    7.6696</td> <td>    0.462</td> <td>   16.608</td> <td> 0.000</td> <td>    6.387</td> <td>    8.952</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>   nan</td> <th>  Durbin-Watson:     </th> <td>   2.461</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td>   nan</td> <th>  Jarque-Bera (JB):  </th> <td>   0.469</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.065</td> <th>  Prob(JB):          </th> <td>   0.791</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 1.636</td> <th>  Cond. No.          </th> <td>    251.</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.986\n",
       "Model:                            OLS   Adj. R-squared:                  0.982\n",
       "Method:                 Least Squares   F-statistic:                     275.8\n",
       "Date:                Fri, 02 Nov 2018   Prob (F-statistic):           7.70e-05\n",
       "Time:                        17:21:35   Log-Likelihood:                 25.097\n",
       "No. Observations:                   6   AIC:                            -46.19\n",
       "Df Residuals:                       4   BIC:                            -46.61\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -0.1880      0.025     -7.471      0.002      -0.258      -0.118\n",
       "x1             7.6696      0.462     16.608      0.000       6.387       8.952\n",
       "==============================================================================\n",
       "Omnibus:                          nan   Durbin-Watson:                   2.461\n",
       "Prob(Omnibus):                    nan   Jarque-Bera (JB):                0.469\n",
       "Skew:                           0.065   Prob(JB):                        0.791\n",
       "Kurtosis:                       1.636   Cond. No.                         251.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "xc = sm.add_constant(x)\n",
    "modelo = sm.OLS(y, xc)\n",
    "resultados = modelo.fit()\n",
    "resultados.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questão 2.**\n",
    "\n",
    "*(Montgomery 12-9)*\n",
    "\n",
    "Os dados abaixo são provenientes de uma pesquisa de satisfação aplicada em um hospital (**também estão disponíveis em [um arquivo CSV](tabela_pacientes.csv)**). \n",
    "\n",
    "|Observation| Age| Severity| Surg_Med| Anxiety| Satisfaction|\n",
    "|---|---|---|---|---|---|\n",
    "|1|55|50| 0| 2.1| 68|\n",
    "|2|46|24| 1| 2.8| 77|\n",
    "|3|30|46| 1| 3.3| 96|\n",
    "|4|35|48| 1| 4.5| 80|\n",
    "|5|59|58| 0| 2.0| 43|\n",
    "|6|61|60| 0| 5.1| 44|\n",
    "|7|74|65| 1| 5.5| 26|\n",
    "|8|38|42| 1| 3.2| 88|\n",
    "|9 |27|42| 0| 3.1| 75|\n",
    "|10|51|50 |1 |2.4 |57 |\n",
    "|11|53|38 |1 |2.2 |56|\n",
    "|12|41|30 |0 |2.1 |88|\n",
    "|13|37|31 |0 |1.9 |88|\n",
    "|14|24|34 |0 |3.1 |102|\n",
    "|15|42|30 |0 |3.0 |88|\n",
    "|16|50|48 |1 |4.2 |70|\n",
    "|17|58|61 |1 |4.6 |52|\n",
    "|18|60|71 |1 |5.3 |43|\n",
    "|19|62|62 |0 |7.2 |46|\n",
    "|20|68|38 |0 |7.8 |56|\n",
    "|21|70|41 |1 |7.0 |59|\n",
    "|22|79|66 |1 |6.2 |26|\n",
    "|23|63|31 |1 |4.1 |52|\n",
    "|24|39|42 |0 |3.5 |83|\n",
    "|25|49|40 |1 |2.1 |75|\n",
    "\n",
    "As variáveis são:\n",
    "\n",
    "* `Age` - a idade do paciente\n",
    "* `Severity` - quão severa é a condição. Valores mais altos indicam condição mais preocupante\n",
    "* `Surg-Med` - Indica se é um paciente de visita ao médico `0` ou cirurgia `1`\n",
    "* `Anxiety` - Índice de ansiedade. Valores mais elevados indicam maior ansiedade\n",
    "\n",
    "Pede-se:\n",
    "\n",
    "**a.** Encontre um modelo de regressão linear múltipla capaz de prever `Satisfaction` a partir da idade, severidade da condição e índice de ansiedade. Escreva a equação.\n",
    "\n",
    "**b.** Interprete os valores $P > |t|$ e a $Prob(\\text{F-statistic})$ indique o que dizem a respeito da qualidade da regressão. Qual a hipótese nula que cada um testa?\n",
    "\n",
    "**c.** Por que é preciso supor que os resíduos do modelo de regressão seguem uma distribuição normal?\n",
    "\n",
    "**d.** O que dizem os testes $Pr(Omnibus)$ e $Pr(JB)$ sobre a normalidade dos resíduos neste caso?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   **Questão 3**\n",
    "\n",
    "*(Montgomery 8-34)*\n",
    "\n",
    "Um artigo no *Journal of Composite Materials* (Dec. 1989, V. 23, p. 1200) descreve o efeito de delaminação na frequência natural de vibração de vigas feitas de materiais compósitos laminados. Cinco de tais vigas foram submetidas a cargas mecânicas, e as frequências encontradas (em hertz) foram as seguintes:\n",
    "\n",
    "`230.66,  233.05,  232.58, 229.48, 232.58`\n",
    "\n",
    "Pede-se:\n",
    "\n",
    "**a.** Verifique se podemos considerar a distribuição de frequências naturais normal. (Dica: *probplot*)\n",
    "\n",
    "**b.** Crie um intervalo de confiança de 95% para a média das frequências naturais.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questão 4**\n",
    "\n",
    "*(Montgomery 8-35)*\n",
    "\n",
    "A agência governamental de meteorologia do governo australiano forneceu os valores de precipitação média para o período 1983-2002 ( [http://www.bom.gov.au/climate/change/rain03.txt](http://www.bom.gov.au/climate/change/rain03.txt) )\n",
    "\n",
    "    499.2, 555.2, 398.8, 391.9, 453.4, 459.8, 483.7, 417.6, 469.2,\n",
    "    452.4, 499.3, 340.6, 522.8, 469.9, 527.2, 565.5, 584.1, 727.3,\n",
    "    558.6, 338.6\n",
    "\n",
    "Pede-se:\n",
    "\n",
    "**a.** Pode-se considerar os níveis de precipitação como vindo de uma distribuição normal?\n",
    "\n",
    "**b.** Sabemos $\\sigma$ ? \n",
    "\n",
    "**c.** Construa um intervalo de confiança de $95\\%$ para a precipitação média anual de chuvas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
